{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T21:47:02.277524Z",
     "start_time": "2019-02-12T21:47:00.909037Z"
    }
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import re\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import bayesian_bootstrap.bootstrap as bb\n",
    "from astropy.utils import NumpyRNGContext\n",
    "\n",
    "from scipy import stats\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T21:47:02.283617Z",
     "start_time": "2019-02-12T21:47:02.280327Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth',500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File/dir locations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T21:47:02.354484Z",
     "start_time": "2019-02-12T21:47:02.348168Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIR = os.getenv(\"DATA_DIR\")\n",
    "filename = \"testing_processed_sampled_taxon_ab_2019-01-21.csv.gz\"\n",
    "filepath = os.path.join(\n",
    "    DATA_DIR, \"processed_journey\",\n",
    "    filename)\n",
    "filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T21:47:04.030281Z",
     "start_time": "2019-02-12T21:47:02.900076Z"
    }
   },
   "outputs": [],
   "source": [
    "# read in processed sampled journey with just the cols we need for related links\n",
    "df = pd.read_csv(filepath, sep =\"\\t\", compression=\"gzip\")\n",
    "# convert from str to list\n",
    "df['Event_cat_act_agg']= df['Event_cat_act_agg'].apply(ast.literal_eval)\n",
    "df['Page_Event_List'] = df['Page_Event_List'].apply(ast.literal_eval)\n",
    "df['Page_List'] = df['Page_List'].apply(ast.literal_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T21:53:36.643691Z",
     "start_time": "2019-02-12T21:53:36.637341Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Page_List_Length'] = df['Page_List'].apply(len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T21:47:04.044448Z",
     "start_time": "2019-02-12T21:47:04.032983Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop dodgy rows, where page variant is not A or B. \n",
    "df = df.query('ABVariant in [\"A\", \"B\"]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers\n",
    "Some rows should be removed before analysis. For example rows with journey lengths of 500 or very high related link click rates. This process might have to happen once features have been created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## journey_click_rate\n",
    "There is no difference in the proportion of journeys using at least one related link (journey_click_rate) between page variant A and page variant B.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "\\frac{\\text{total number of journeys including at least one click on a related link}}{\\text{total number of journeys}}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Related link prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T21:47:06.719452Z",
     "start_time": "2019-02-12T21:47:06.714197Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_number_of_events_rl(event):\n",
    "    \"\"\"Counts events with category 'relatedLinkClicked' and action'Related content'.\"\"\"\n",
    "    if event[0][0] == 'relatedLinkClicked' and 'Related content' in event[0][1]:\n",
    "        return event[1]\n",
    "    return 0\n",
    "\n",
    "\n",
    "def sum_related_click_events(event_list):\n",
    "    return sum([get_number_of_events_rl(event) for event in event_list])\n",
    "\n",
    "\n",
    "def is_related(x):\n",
    "    \"\"\"Compute whether a journey includes at least one related link click.\"\"\"\n",
    "    return x > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T21:47:07.335576Z",
     "start_time": "2019-02-12T21:47:07.319772Z"
    }
   },
   "outputs": [],
   "source": [
    "# get the number of related links clicks per Sequence\n",
    "df['Related Links Clicks per seq'] = df['Event_cat_act_agg'].map(sum_related_click_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T21:47:07.802148Z",
     "start_time": "2019-02-12T21:47:07.793413Z"
    }
   },
   "outputs": [],
   "source": [
    "# map across the Sequence variable, which includes pages and Events\n",
    "# we want to pass all the list elements to a function one-by-one and then collect the output.\n",
    "df[\"Has_Related\"] = df[\"Related Links Clicks per seq\"].map(is_related)\n",
    "\n",
    "df['Related Links Clicks row total'] = df['Related Links Clicks per seq'] * df['Occurrences']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T21:47:08.286435Z",
     "start_time": "2019-02-12T21:47:08.254998Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequentist statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T21:47:10.048293Z",
     "start_time": "2019-02-12T21:47:10.043739Z"
    }
   },
   "outputs": [],
   "source": [
    "n = df.Occurrences.sum()\n",
    "# prop of journeys with at least one related link\n",
    "p = df.Has_Related.sum() / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T21:47:10.655968Z",
     "start_time": "2019-02-12T21:47:10.651021Z"
    }
   },
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T21:47:12.076072Z",
     "start_time": "2019-02-12T21:47:12.057356Z"
    }
   },
   "outputs": [],
   "source": [
    "# using Bernoulli trial terminology\n",
    "# total occurrences, both A and B\n",
    "# assume non- A and B were dropped\n",
    "n = df.Occurrences.sum()\n",
    "# prop of journeys with at least one related link\n",
    "p = df.Has_Related.sum() / n\n",
    "\n",
    "assert (p >= 0),\"Prop less than zero!\"\n",
    "assert (p <= 1),\"Prop greater than one!\"\n",
    "\n",
    "\n",
    "# number of trials for page A\n",
    "n_a = df[df.ABVariant == \"A\"].Occurrences.sum()\n",
    "# number of successes for page A, at least one related link clicked\n",
    "x_a = df[df.ABVariant == \"A\"].Has_Related.sum()\n",
    "# prop of journeys where one related link was clicked, on A\n",
    "p_a = x_a / n_a\n",
    "\n",
    "\n",
    "# number of trials for page B\n",
    "n_b = df[df.ABVariant == \"B\"].Occurrences.sum()\n",
    "# number of successes for page B, at least one related link clicked\n",
    "x_b = df[df.ABVariant == \"B\"].Has_Related.sum()\n",
    "# prop of journeys where one related link was clicked, on B\n",
    "p_b = x_b / n_b\n",
    "\n",
    "assert (n == n_a + n_b), \"Error in filtering by ABVariant!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistical significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T21:47:14.231597Z",
     "start_time": "2019-02-12T21:47:14.228700Z"
    }
   },
   "outputs": [],
   "source": [
    "# help(proportions_ztest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T21:47:14.787424Z",
     "start_time": "2019-02-12T21:47:14.780041Z"
    }
   },
   "outputs": [],
   "source": [
    "# using statsmodels\n",
    "# successes\n",
    "count = np.array([x_a, x_b])\n",
    "# number of trials\n",
    "nobs = np.array([n_a, n_b])\n",
    "# z prop test\n",
    "z,p_value = proportions_ztest(count, nobs, value=0, alternative='two-sided')\n",
    "print(' z-stat = {z} \\n p-value = {p_value}'.format(z=z,p_value=p_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Practical significance - uplift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T21:47:18.859923Z",
     "start_time": "2019-02-12T21:47:18.853134Z"
    }
   },
   "outputs": [],
   "source": [
    "# uplift\n",
    "def compute_standard_error_prop_two_samples(x_a, n_a, x_b, n_b, alpha=0.05):\n",
    "    p1 = x_a/n_a\n",
    "    p2 = x_b/n_b    \n",
    "    se = p1*(1-p1)/n_a + p2*(1-p2)/n_b\n",
    "    return np.sqrt(se)\n",
    "    \n",
    "def zconf_interval_two_samples(x_a, n_a, x_b, n_b, alpha=0.05):\n",
    "    p1 = x_a/n_a\n",
    "    p2 = x_b/n_b    \n",
    "    se = compute_standard_error_prop_two_samples(x_a, n_a, x_b, n_b)\n",
    "    z_critical = stats.norm.ppf(1-0.5*alpha)\n",
    "    return p2-p1-z_critical*se, p2-p1+z_critical*se\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T21:47:19.624111Z",
     "start_time": "2019-02-12T21:47:19.618373Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Due to multiple testing we used the Bonferroni correction for alpha\n",
    "ci_low,ci_upp = zconf_interval_two_samples(x_a, n_a,\n",
    "                                           x_b, n_b, alpha = 0.01)\n",
    "print(' 95% Confidence Interval = ( {0:.2f}% , {1:.2f}% )'\n",
    "      .format(100*ci_low, 100*ci_upp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T19:54:09.572864Z",
     "start_time": "2019-02-12T19:54:05.128Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://medium.com/@thibalbo/coding-bayesian-ab-tests-in-python-e89356b3f4bd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be developed, a Bayesian approach can provide a simpler interpretation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ratio of clicks on navigation elements vs. clicks on related links\n",
    "\n",
    "There is no statistically significant difference in the ratio of clicks on navigation elements vs. clicks on related links between page variant A and page variant B\n",
    "\n",
    "\\begin{equation*}\n",
    "\\frac{\\text{total number of navigation element click events from content pages}}{\\text{total number of related link click events}}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Navigation events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T20:32:41.568599Z",
     "start_time": "2019-02-12T20:32:41.562541Z"
    }
   },
   "outputs": [],
   "source": [
    "def is_nav_event(event):\n",
    "    \"\"\"\n",
    "    Return the total number of related links clicks for that row.\n",
    "    \n",
    "    Clicks per sequence multiplied by occurrences. \n",
    "    \"\"\"\n",
    "    return any(\n",
    "        ['breadcrumbClicked' in event, 'homeLinkClicked' in event,\n",
    "         all(cond in event for cond in [\n",
    "             'relatedLinkClicked','Explore the topic'])])\n",
    "\n",
    "\n",
    "def count_nav_events(page_event_list):\n",
    "    content_page_nav_events = 0\n",
    "    for pair in page_event_list:\n",
    "        if is_nav_event(pair[1]):\n",
    "            if pair[0] in thing_page_paths:\n",
    "                content_page_nav_events += 1\n",
    "    return content_page_nav_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need finding thing list\n",
    "df_finding_thing = pd.read_csv(\n",
    "    '../../data/raw_bq_extract/document_types.csv.gz',\n",
    "             sep=\"\\t\", compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T20:32:41.826248Z",
     "start_time": "2019-02-12T20:32:41.571496Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['Content_page_nav_events'] = df['Page_Event_List'].map(count_nav_events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## proportion of journeys with a page sequence including content and related links only\n",
    "\n",
    "There is no statistically significant difference in the proportion of journeys with a page sequence including content and related links only (including loops) between page variant A and page variant B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "\\frac{\\text{total number of journeys that only contain content pages and related links (i.e. no nav pages)}}{\\text{total number of journeys}}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian bootstrap for non-parametric hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://savvastjortjoglou.com/nfl-bayesian-bootstrap.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T22:00:47.622429Z",
     "start_time": "2019-02-12T22:00:47.613975Z"
    }
   },
   "outputs": [],
   "source": [
    "# let's use mean journey length (could probably model parametrically but we use it for demonstration here)\n",
    "# some journeys have legnth 500 and should probably be removed as they are liekely bots or other weirdness\n",
    "\n",
    "# need to roll out the data, deaggregate on one variable of interest\n",
    "# we want to repeat each row's journey length by it's occurrences\n",
    "# so more common journey lengths are more likely to be sampled\n",
    "print(df['Page_List_Length'].head())\n",
    "print(df['Occurrences'].head())\n",
    "\n",
    "np.repeat(df['Page_List_Length'].head(), df['Occurrences'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T22:22:07.499899Z",
     "start_time": "2019-02-12T22:22:07.483883Z"
    }
   },
   "outputs": [],
   "source": [
    "a_len = np.repeat(df[df.ABVariant == \"A\"].Page_List_Length, df[df.ABVariant == \"A\"].Occurrences)\n",
    "a_len.values\n",
    "\n",
    "b_len = np.repeat(df[df.ABVariant == \"B\"].Page_List_Length, df[df.ABVariant == \"B\"].Occurrences)\n",
    "b_len.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the style for our plots\n",
    "sns.set(style='white', palette='colorblind', font_scale=1.3,\n",
    "        rc={'figure.figsize':(12,9), \n",
    "            \"axes.facecolor\": (0, 0, 0, 0)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T22:23:03.379643Z",
     "start_time": "2019-02-12T22:23:03.374997Z"
    }
   },
   "outputs": [],
   "source": [
    "help(bb.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T22:23:46.581472Z",
     "start_time": "2019-02-12T22:23:42.762556Z"
    }
   },
   "outputs": [],
   "source": [
    "# for reproducibility, set the seed within this context\n",
    "with NumpyRNGContext(1337):\n",
    "    a_bootstrap = bb.mean(a_len.values, n_replications=10000)\n",
    "    b_bootstrap = bb.mean(b_len.values, n_replications=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T22:25:23.694236Z",
     "start_time": "2019-02-12T22:25:23.355573Z"
    }
   },
   "outputs": [],
   "source": [
    "ax = sns.distplot(a_bootstrap, color='salmon')\n",
    "ax.set(xlabel='Journey Length', ylabel='Density', title='Page Variant A Mean Journey Length')\n",
    "sns.despine();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T22:26:41.960973Z",
     "start_time": "2019-02-12T22:26:41.951879Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate a 95% HDI\n",
    "a_ci_low, a_ci_hi = bb.highest_density_interval(a_bootstrap)\n",
    "print('low ci:', a_ci_low, '\\nhigh ci:', a_ci_hi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T22:27:48.663720Z",
     "start_time": "2019-02-12T22:27:48.273953Z"
    }
   },
   "outputs": [],
   "source": [
    "ax = sns.distplot(a_bootstrap, color='salmon')\n",
    "ax.plot([a_ci_low, a_ci_hi], [0, 0], linewidth=10, c='k', marker='o', \n",
    "         label='95% HDI')\n",
    "ax.set(xlabel='Journey Length', ylabel='Density', title='Page Variant A Mean Journey Length')\n",
    "sns.despine()\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T22:32:42.990066Z",
     "start_time": "2019-02-12T22:32:42.980495Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate a 95% HDI\n",
    "b_ci_low, b_ci_hi = bb.highest_density_interval(b_bootstrap)\n",
    "print('low ci:', b_ci_low, '\\nhigh ci:', b_ci_hi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T22:33:32.856617Z",
     "start_time": "2019-02-12T22:33:32.471005Z"
    }
   },
   "outputs": [],
   "source": [
    "ax = sns.distplot(b_bootstrap)\n",
    "ax.plot([b_ci_low, b_ci_hi], [0, 0], linewidth=10, c='k', marker='o', \n",
    "         label='95% HDI')\n",
    "ax.set(xlabel='Journey Length', ylabel='Density', title='Page Variant B Mean Journey Length')\n",
    "sns.despine()\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T22:34:35.273769Z",
     "start_time": "2019-02-12T22:34:34.743675Z"
    }
   },
   "outputs": [],
   "source": [
    "ax = sns.distplot(b_bootstrap, label='B')\n",
    "ax = sns.distplot(a_bootstrap, label='A', ax=ax, color='salmon')\n",
    "ax.set(xlabel='Journey Length', ylabel='Density')\n",
    "sns.despine()\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also measure the uncertainty in the difference between the Page Variants's Journey Length by subtracting their posteriors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T22:44:18.998325Z",
     "start_time": "2019-02-12T22:44:18.988223Z"
    }
   },
   "outputs": [],
   "source": [
    "# calculate the posterior for the difference between A's and B's YPA\n",
    "ypa_diff = np.array(b_bootstrap) - np.array(a_bootstrap)\n",
    "# get the hdi\n",
    "ypa_diff_ci_low, ypa_diff_ci_hi = bb.highest_density_interval(ypa_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T22:44:35.508949Z",
     "start_time": "2019-02-12T22:44:35.504022Z"
    }
   },
   "outputs": [],
   "source": [
    "# the mean of the posterior\n",
    "ypa_diff.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T22:45:14.626773Z",
     "start_time": "2019-02-12T22:45:14.622273Z"
    }
   },
   "outputs": [],
   "source": [
    "print('low ci:', ypa_diff_ci_low, '\\nhigh ci:', ypa_diff_ci_hi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T22:47:12.970665Z",
     "start_time": "2019-02-12T22:47:12.573237Z"
    }
   },
   "outputs": [],
   "source": [
    "ax = sns.distplot(ypa_diff)\n",
    "ax.plot([ypa_diff_ci_low, ypa_diff_ci_hi], [0, 0], linewidth=10, c='k', marker='o', \n",
    "         label='95% HDI')\n",
    "ax.set(xlabel='Journey Length', ylabel='Density', \n",
    "       title='The difference between B\\'s and A\\'s mean Journey Length')\n",
    "sns.despine()\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can actually calculate the probability that B's mean Journey Length was greater than A's mean Journey Length by measuring the proportion of values greater than 0 in the above distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T22:49:17.684166Z",
     "start_time": "2019-02-12T22:49:17.679319Z"
    }
   },
   "outputs": [],
   "source": [
    "# We count the number of values greater than 0 and divide by the total number\n",
    "# of observations\n",
    "# which returns us the the proportion of values in the distribution that are\n",
    "# greater than 0, could act a bit like a p-value\n",
    "(ypa_diff > 0).sum() / ypa_diff.shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "220.15px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
